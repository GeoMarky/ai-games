{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzgAAACkCAYAAABbwIsnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAewgAAHsIBbtB1PgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAT3ElEQVR4nO3de9BdVX3G8edJQgjIVYIgRIqIlahYL8SBCgoFO16wYxEQFBULtWjHQbSKWixoxyuKdUpFWy8gapWIyG3UAhYURQVHxAsakYLcCSAEFBJJfv1jrePZCe973ktyztp7ne9n5kz2fs/Km9/snMt+1l57LUeEAAAAAKAGc0oXAAAAAAAbCgEHAAAAQDUIOAAAAACqQcABAAAAUA0CDgAAAIBqEHAAAAAAVIOAAwAAAKAaBBwAAAAA1SDgAAAAAKgGAQcAAABANQg4AAAAAKpBwAEAAABQDQIOAAAAgGoQcAAAAABUg4ADAAAAoBoEHAAAAADVmDfqf9D2xpJ2z7vLJa0edQ0AAAAAWmGupG3z9k8jYuX6/sKRBxylcHNlgX8XAAAAQHstkXTV+v4ShqgBAAAAqEaJKzjLC/ybdfiHy0pX0Ek3XXNs6RI65/knLChdQiddtMX3S5fQORf87LTSJXTSc9/x6NIldM4Wr+O7YDZOOZBBNzO18Qv2KV1Cp6xY87A+/tDNvd0NkhNKBBzuuZmtzbcvXUEnLVowv3QJnTN/OwLObCzaqnQF3bPNbduULqGTdpyzsHQJnbPllnNLl9BJWzx2UekSOmfBnI1Kl9BlGyQnMEQNAAAAQDUIOAAAAACqQcABAAAAUA0CDgAAAIBqEHAAAAAAVIOAAwAAAKAaBBwAAAAA1SDgAAAAAKgGAQcAAABANQg4AAAAAKpBwAEAAABQDQIOAAAAgGoQcAAAAABUg4ADAAAAoBoEHAAAAADVIOAAAAAAqAYBBwAAAEA1CDgAAAAAqkHAAQAAAFANAg4AAACAahBwAAAAAFSDgAMAAACgGgQcAAAAANUg4AAAAACoBgEHAAAAQDUIOAAAAACqQcABAAAAUA0CDgAAAIBqEHAAAAAAVIOAAwAAAKAaBBwAAAAA1SDgAAAAAKgGAQcAAABANQg4AAAAAKpBwAEAAABQDQIOAAAAgGoQcAAAAABUg4ADAAAAoBoEHAAAAADVIOAAAAAAqAYBBwAAAEA1CDgAAAAAqkHAAQAAAFANAg4AAACAahBwAAAAAFSDgAMAAACgGgQcAAAAANUg4AAAAACoBgEHAAAAQDUIOAAAAACqQcABAAAAUA0CDgAAAIBqEHAAAAAAVIOAAwAAAKAaBBwAAAAA1SDgAAAAAKgGAQcAAABANQg4AAAAAKpBwAEAAABQDQIOAAAAgGoQcAAAAABUg4ADAAAAoBoEHAAAAADVIOAAAAAAqAYBBwAAAEA1CDgAAAAAqkHAAQAAAFANAg4AAACAahBwAAAAAFSDgAMAAACgGgQcAAAAANUg4AAAAACoBgEHAAAAQDXmFfg35xb4N+tw/+2lK+ikmx9aVbqEzll1B30fs3Hzg6Ur6J677767dAmddMuaKF1C59x/3+rSJXTSittuLl1C56xc88fSJXTKijUPN3c3SE5wxGg/JG3vIenKkf6jAAAAANpuSURctb6/hG5aAAAAANUocQVnY0m7593lktpyzXh79a8sLZHEeLDp4bjNHMdsdjhuM8cxmx2O28xxzGaH4zZzHLPZafNxmytp27z904hYub6/cOT34OSi1/vS04Zmu7l7e0Qw6HQaOG4zxzGbHY7bzHHMZofjNnMcs9nhuM0cx2x2OnDcbtyQv4whagAAAACqQcABAAAAUA0CDgAAAIBqEHAAAAAAVIOAAwAAAKAaBBwAAAAA1SDgAAAAAKjGyBf6BAAAAIBh4QoOAAAAgGoQcAAAAABUg4ADAAAAoBoEHAAAAADVIOAAAAAAqAYBBwAAAEA1CDgAAAAAqkHAAQAAAFANAg4AAACAahBwAAAAAFSDgCPJ9k62P2z7Wtu/t32P7R/a/ifbm5aur01sP8b2gbbfY/vrtu+yHflxeun62sr2M22/Mx+zm2yvtP2A7WW2T7e9T+ka28T2FrYPs/0R25fZvs72fbZX2b7T9qW232Z7m9K1doXtDzXeq2F739I1tcU6x2XQ49LStbaV7YX5Pfld27fnz7hbbf/A9sm29ypdY2n5c2u6rzXepxOwPd/2Uba/Yfu2xnfpr2x/xvaepWtsG9sLbL/B9iW2l+fv0VtsX2j75aXrGxZHROkairL9YklfkLTlJE1+JelFEXH96KpqL9uDXjBnRMSRo6qlK2xfJum502h6pqSjI2LVkEtqPdsHSLpoGk3vknRERHxzyCV1mu2/kHSVpHmNH+8XEZeWqahdpvhca7osIvYdZi1dZPsQSadJGtThcG5EvHREJbVSDsjPm8FfWSNpp4i4ZTgVdYvtx0m6UNLuUzT9qKS3xLif4Eqy/SRJ50p60oBm35B0cET8fjRVjca8qZvUK3/pnyVpU0kPSHq/pP+VtImkwyT9vdKL4kLbSyLigVK1ttRNkq6V9NelC2m5HfOft0paKuk7kn4raa6kvSS9Jbd5ldJ78hUFamyjm5Tejz/K27cpXXVeJOlgSQdJWijpvPz+vKZUoW1me46k/1J6bd0p6TFlK2q10yR9fMDzVZ0AbAi2Xy3ps0rvzTuVjuHlku6RtL2kJ0h6iaQ/lqqxRV4r6VFTtHmypC/n7UsIN4nteVo73Fwj6RSlTujNJe2t9F36KEnHKX1fnDz6StvD9rZKHYWPyz9aKukMpXORHSS9RtIhkl4g6b8l/U2BMocnIsb2oXTyFEofvHtN8Pxb8/Mh6V9K19uGh6R3SzpQ0nZ5f+fGMTq9dH1tfEi6QNKhkuZO8vxCpQ/p3nHcp3TNpR+THat12ry0cczOLl1zWx+S3pSP0bWS3tc4ZvuWrq0tj8YxOal0LV16SFos6aF87L4tacsBbeeXrrcLD0kfbLwejyhdT1sekl7WOC7fm+g7QtKzJK3Kbe6RNK903YWP2alTfbblc7pem4NK17whH2N7D47tJZL2zbufjogrJmj2EaWTAkl6k+2NRlFbm0XEiRFxQUTcUbqWroiIAyPirIhYPcnzdyn1PPUcPJrK2muyY7VOm69J+mXenc4QwLGTh3T8a959vdKXP7Ch/LukjZWGih4UEfdN1jAYejulfLX1lXn3AUlfLVhO2zynsf3+ib4jIuJHSh2KkrS1pN1GUVgb2Z6r/mvpRvW/B9b1HqURJZL0jmHXNUpjG3CUen97PjtRg4hYI+lzeXdr9QMRsKFd2th+QqkiOqg3ZGhB0Sra6+OSNlO6P+7SwrWgIrZ3k7R/3j01d9Rg/eyv/pDmr0TEH0oW0zLzG9uD7on+TWN74yHV0gVPlLRV3r5oQAfravXvd93D9s7DL200xjng9Gat+r3SGP/JXNbY3nt45WDMNT+81xSrokNsL5b09Lz7y0Ftx5HtQ5WGk96jNNwW2JAOaWwv7W3Y3tr2E5nhcFZe3dj+3KStxtOyxvYuA9r1OghD0q+HV07rPbqxPdWIm+bz1YyGGOeAszj/eV1EPDygXfPEafGkrYD105xZh5P1SdjeNJ88vVnpHrq5+amPFSyrdWxvpf4xOT4ilpesp0MOydPNPmj7ftu/tn2G7f1KF9ZCvel475N0re1X2v6JUqBeJuku29fbPtH2ZsWq7Ih8jP427/5Wa1/VR7oJfkXePj4PwVqL7WdIenHe/VJErFi3zRhpTogy2SzBEz3/5CHUUsRYBhzbC5Ru7Jakmwe1jYjfqf9CedygtsBs5HHXb2/86KxStbSR7SN7a0IovReXKd0ft11u8mGlqd7R9yGlGay+J+nThWvpkidL+nOlIY+bSdpVqVf9W7bPsT3VicI46Z0I3aB0L87nJT1tnTaPl3SSpCts7zCyyrrpZerPsHZm5DvAkeROmiMlPah0P86Vtl9te0/bB9g+UWnEzXxJV0t6c7Fi2+E69WcunOqqTPP5nYZTzuiNZcBRmlKwZzpTP/cCDr1QGIbjJD07b58TEVeVLKZDrpa0Z0S8lZOBPtt7Szpa0sOSjuHYTMsfJH1JaWmAfSQ9Q2n6+/dKuju3eamkc5ls5k96Q2B2k/SPku6VdIzSNOQLJC2R9PXc5qmSlubOHEyM4WlTiIhzJO2h1GnzdKUpj69QuofkJKX38Zsl7R0RtxcqsxUirWlzSd59mu3DJ2qXf95cV2jzidp10bh+2DRvSJ7OzC4r85+bDKEWjDHbz5P0gbx7p9JMV1jb15Q+gHdXCoKHSzpH6QvuC7YPLFhbq9ieL+k/JVnSRyPip4VL6oodI+LwiPhURFweEVdHxEURcYKkp0j6cW73PPEe7eldbdhY0mpJL4yIT0bE8ohYmTtqDlQ/5Pyl0tpVWIftRepPYvT9iFg2oPnYyp0Lr1BaV8kTNNlO6fth3xGW1WYnKnV0SdIZtk+wvZPtjfKfJyiFxOZ5cDXnueMacB5qbM+ftFVfbyaOB4dQC8aU7aconajPUwrRhzL99iNFxL0R8bP8uDIivhQRByn1eO6i1Kt+ZNkqW+OdSvcK/lZpfQNMQ0TcO+C5O5Smbu+dBLxxJEW1X/N7dGlEfH/dBnkm0uYEFxP2IkNHqH8+dkbJQtrK9qMkXSzpnyVtozQMd7HS+dmWSldcL1e6cni+7WMLldoaEfFDSUcpfXZtpDRV9I15vzd19BytvUzF/SMuc2jGNeA0/wOnM+ys11M1neFswJRsP17S/yhNP75a0uERcdngv4WmiDhTafamOZJOtb114ZKKytP29tYxeGMeooANICKuV38q1V25n0TS2t+jX5+sUUT8XNIteXfJUCvqrlflP1dK+nLJQlrs3erfK3JURBwfEb+MiFURsSIiLpK0n9LkM5Z0iu117wkbOxHxOaWRD0u19nt2jdIQtudo7Qktfjey4oZsXukCSoiIh2zfpTTRwKJBbfNJUy/g3DTs2lC/fHJ0saQdlKay/Ls8thgzd66kQ5Xeoy+U9MWy5RR1nNIV6eslbWr7sAnaPLWx/Ve2t8/b5xOIpvQL9Wdo2lHSrQVraYOblCaykKaYrCe33VHp/hw02N5D/QkbLsgTG6HBtiW9Nu8ui4gJr3JFxMO236V0JWdO/jvHjabK9oqIn0g6NM8891il2zRu7a2zZPsVjea/KFDiUIxlwMmuVbqZdFfb8wZMFb3bOn8HmDXbC5V6gnvz+L8x97BgdprTH/9ZsSraoTeUdhelKVWn8q7G9uO19rSieKSJxvyPs5+rf0XmEVP2rqP3/KAlGcZVc3IBhqdNbDv1J7X48aCGWntdw90mbTWG8qKeE3VGNNd4/MGIyhm6cR2iJqWEL6We32cNaNdcn+S7wysHtctTzH5T/d66t0fEfxQsqQY7NrYZQophaq4PMe5XbyTp243tJ0zaKul16NwysNWYyTfN9660LteAoX5jrhmMp+qYb85ySKCeQp6Y5uC8e4vS0gJVGOeA87XG9msnapCntOz1rtyrNLYTmDHbm0q6UNIz84/eGxEfLFhSLZqrqY/1jGERcWREeNBDa088sF/juRsKld0JtneR9Py8e31EcKIunaf+OhuTzo6WZ4rcJu9+Z9hFdcwLJW2bt784xaLj4+we9Rf53Mv2oJDT7JT+v+GVVI1j1X8NfiJf5anC2AacPLtE78P2KNt7TdDsLUqzdEjSxyLijxO0AQbKPSTnKN3MJ6XX0gkFS2q9vLjnginaHCfpRXn3BvWvygLTZvslg06YbG8n6Svq9wxz1VVSRNwt6VN59/kT3fNle3NJ/9b40SdHUVuHsPbNNOTZ+C7MuzsozaT2CPme6WbH4QVDLq31bE+6cKftlyit9SVJv1ZaNLsaHuc14Gw/Q2nY2SZKw1vep3SVZhOly8avy02XSdojIqqZPm+28iKCuzZ+tFDSyXn7u+p/4UmSIuL00VTWXrbPVr+H81uS3qQ0ucBkVo37Ogi2b1BacOxspeDyG6X36OZK6+G8Uv3AuErSiyPi4tFX2i22T1JaG0FKV3AuLVdNO+TX2kZKr7UrlMLyg0qfbfsqLV7ZuwJxuaQDImLlur9nHNneVtJVSqufPyzpE5K+qtTbvruk49W/D+K0iHhDiTrbKJ+M36Z079zPImL3Kf7KWMuzRP5I0qb5R+cr3bN0vdJN83sqfbf2TugviYgDRl1n29heofS5tlTpvrlVknZWGv3w8tzsd5L2j4ip7m/qlLEOONKfEuznJW0xSZNlSidP142uqvayfbqk10y3fR4WM9Zsz/RNdmNE7DyMWroin3ROZ9KAm5VmobtoypYg4ExgBq+1syUdPWjNnHFke7HScLVdBzT7jKRjGAXRZ/sYSafl3bdFxMmD2kOyfYDSBCoLp2j6LUkHMyOdZPsB9WcCnsgvJB1RW7iRxnsWNUlSRJyf50o/VmkK0EVKCfc6pcR7am8qPQAjs7+kA5TWNVisNIvONkqLC94h6Wql4Qdn8f7EenqN0rj9vZRuhl+o1OH1gNL0xt+TdEZEXFGswhaLiGttP13S65VuVn6i0vpydypd1f9kRHD/6iP11r5ZLekLJQvpioi4OF/JOUrp/qWnSNpK6erh7ZKuVFoq4LwY9977vqOVFkF9ttIU0ZspTWhxjdLQ2zNr7XgY+ys4AAAAAOoxtpMMAAAAAKgPAQcAAABANQg4AAAAAKpBwAEAAABQDQIOAAAAgGoQcAAAAABUg4ADAAAAoBoEHAAAAADVIOAAAAAAqAYBBwAAAEA1CDgAAAAAqkHAAQAAAFANAg4AAACAahBwAAAAAFSDgAMAAACgGgQcAAAAANUg4AAAAACoBgEHAAAAQDUIOAAAAACqQcABAAAAUA0CDgAAAIBqEHAAAAAAVIOAAwAAAKAaBBwAAAAA1fh/mmCiinXqjfMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [01:44<00:00, 20.85s/it]\n",
      "100%|██████████| 4/4 [00:55<00:00, 13.94s/it]\n",
      "100%|██████████| 3/3 [00:32<00:00, 10.67s/it]\n",
      "100%|██████████| 3/3 [04:45<00:00, 95.20s/it]\n",
      "100%|██████████| 3/3 [02:33<00:00, 51.21s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [01:24<00:00, 42.24s/it]\n",
      "100%|██████████| 3/3 [00:41<00:00, 13.73s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [02:52<00:00, 57.38s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 4/4 [01:10<00:00, 17.55s/it]\n",
      "100%|██████████| 2/2 [00:47<00:00, 23.82s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:32<00:00, 10.71s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [01:22<00:00, 27.58s/it]\n",
      "100%|██████████| 4/4 [01:12<00:00, 18.08s/it]\n",
      "100%|██████████| 4/4 [01:35<00:00, 23.94s/it]\n",
      "100%|██████████| 2/2 [01:00<00:00, 30.47s/it]\n",
      "100%|██████████| 2/2 [00:26<00:00, 13.49s/it]\n",
      "100%|██████████| 5/5 [00:28<00:00,  5.74s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "100%|██████████| 4/4 [00:19<00:00,  4.84s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [01:24<00:00, 28.27s/it]\n",
      "100%|██████████| 3/3 [00:32<00:00, 10.74s/it]\n",
      "100%|██████████| 3/3 [00:39<00:00, 13.14s/it]\n",
      "100%|██████████| 4/4 [01:51<00:00, 27.79s/it]\n",
      "100%|██████████| 3/3 [02:48<00:00, 56.01s/it]\n",
      "100%|██████████| 3/3 [01:01<00:00, 20.49s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [03:11<00:00, 95.59s/it]\n",
      "100%|██████████| 4/4 [01:09<00:00, 17.40s/it]\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.05s/it]\n",
      "100%|██████████| 3/3 [01:52<00:00, 37.67s/it]\n",
      "100%|██████████| 3/3 [02:19<00:00, 46.63s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 4/4 [01:01<00:00, 15.32s/it]\n",
      "100%|██████████| 3/3 [01:11<00:00, 23.84s/it]\n",
      "100%|██████████| 3/3 [00:28<00:00,  9.38s/it]\n",
      "100%|██████████| 4/4 [01:29<00:00, 22.27s/it]\n",
      "100%|██████████| 3/3 [03:17<00:00, 65.92s/it]\n",
      "100%|██████████| 3/3 [01:16<00:00, 25.60s/it]\n",
      "100%|██████████| 2/2 [01:14<00:00, 37.06s/it]\n",
      "100%|██████████| 3/3 [01:11<00:00, 23.93s/it]\n",
      "100%|██████████| 3/3 [02:48<00:00, 56.20s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [01:08<00:00, 22.90s/it]\n",
      "100%|██████████| 3/3 [01:47<00:00, 35.92s/it]\n",
      "100%|██████████| 2/2 [00:36<00:00, 18.05s/it]\n",
      "100%|██████████| 4/4 [00:31<00:00,  7.86s/it]\n",
      "100%|██████████| 2/2 [03:11<00:00, 95.79s/it]\n",
      "100%|██████████| 2/2 [01:10<00:00, 35.25s/it]\n",
      "100%|██████████| 3/3 [02:43<00:00, 54.55s/it]\n",
      "100%|██████████| 6/6 [01:04<00:00, 10.81s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:09<00:00,  3.12s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:29<00:00,  9.77s/it]\n",
      "100%|██████████| 3/3 [00:52<00:00, 17.48s/it]\n",
      "100%|██████████| 3/3 [00:25<00:00,  8.57s/it]\n",
      "100%|██████████| 3/3 [00:42<00:00, 14.11s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:38<00:00, 12.69s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [02:07<00:00, 42.47s/it]\n",
      "100%|██████████| 3/3 [00:32<00:00, 10.83s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:13<00:00,  4.59s/it]\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.69s/it]\n",
      "100%|██████████| 4/4 [00:49<00:00, 12.43s/it]\n",
      "100%|██████████| 2/2 [01:52<00:00, 56.32s/it]\n",
      "100%|██████████| 4/4 [03:46<00:00, 56.56s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [01:34<00:00, 31.48s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [01:52<00:00, 22.47s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [04:47<00:00, 95.95s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:38<00:00, 19.12s/it]\n",
      "100%|██████████| 3/3 [04:38<00:00, 92.90s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:58<00:00, 11.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from lightgbm import LGBMClassifier\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Process, Queue, current_process, Manager\n",
    "import pdb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "import random\n",
    "\n",
    "data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\n",
    "training_path = data_path / 'training'\n",
    "evaluation_path = data_path / 'evaluation'\n",
    "test_path = data_path / 'test'\n",
    "training_tasks = sorted(os.listdir(training_path))\n",
    "eval_tasks = sorted(os.listdir(evaluation_path))\n",
    "\n",
    "cmap = colors.ListedColormap(\n",
    "    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "norm = colors.Normalize(vmin=0, vmax=9)\n",
    "# 0:black, 1:blue, 2:red, 3:greed, 4:yellow,\n",
    "# 5:gray, 6:magenta, 7:orange, 8:sky, 9:brown\n",
    "plt.figure(figsize=(5, 2), dpi=200)\n",
    "plt.imshow([list(range(10))], cmap=cmap, norm=norm)\n",
    "plt.xticks(list(range(10)))\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "def Defensive_Copy(A): \n",
    "    n = len(A)\n",
    "    k = len(A[0])\n",
    "    L = np.zeros((n,k), dtype = int)\n",
    "    for i in range(n):\n",
    "        for j in range(k):\n",
    "            L[i,j] = 0 + A[i][j]\n",
    "    return L.tolist()\n",
    "\n",
    "def Create(task, task_id = 0):\n",
    "    n = len(task['train'])\n",
    "    Input = [Defensive_Copy(task['train'][i]['input']) for i in range(n)]\n",
    "    Output = [Defensive_Copy(task['train'][i]['output']) for i in range(n)]\n",
    "    Input.append(Defensive_Copy(task['test'][task_id]['input']))\n",
    "    return Input, Output\n",
    "\n",
    "def Recolor(task):\n",
    "    Input = task[0]\n",
    "    Output = task[1]\n",
    "    Test_Picture = Input[-1]\n",
    "    Input = Input[:-1]\n",
    "    N = len(Input)\n",
    "    \n",
    "    for x, y in zip(Input, Output):\n",
    "        if len(x) != len(y) or len(x[0]) != len(y[0]):\n",
    "            return -1\n",
    "        \n",
    "    Best_Dict = -1\n",
    "    Best_Q1 = -1\n",
    "    Best_Q2 = -1\n",
    "    Best_v = -1\n",
    "    # v ranges from 0 to 3. This gives an extra flexibility of measuring distance from any of the 4 corners\n",
    "    Pairs = []\n",
    "    for t in range(15):\n",
    "        for Q1 in range(1,8):\n",
    "            for Q2 in range(1,8):\n",
    "                if Q1+Q2 == t:\n",
    "                    Pairs.append((Q1,Q2))\n",
    "                    \n",
    "    for Q1, Q2 in Pairs:\n",
    "        for v in range(4):\n",
    "    \n",
    "  \n",
    "            if Best_Dict != -1:\n",
    "                continue\n",
    "            possible = True\n",
    "            Dict = {}\n",
    "                      \n",
    "            for x, y in zip(Input, Output):\n",
    "                n = len(x)\n",
    "                k = len(x[0])\n",
    "                for i in range(n):\n",
    "                    for j in range(k):\n",
    "                        if v == 0 or v ==2:\n",
    "                            p1 = i%Q1\n",
    "                        else:\n",
    "                            p1 = (n-1-i)%Q1\n",
    "                        if v == 0 or v ==3:\n",
    "                            p2 = j%Q2\n",
    "                        else :\n",
    "                            p2 = (k-1-j)%Q2\n",
    "                        color1 = x[i][j]\n",
    "                        color2 = y[i][j]\n",
    "                        if color1 != color2:\n",
    "                            rule = (p1, p2, color1)\n",
    "                            if rule not in Dict:\n",
    "                                Dict[rule] = color2\n",
    "                            elif Dict[rule] != color2:\n",
    "                                possible = False\n",
    "            if possible:\n",
    "                \n",
    "                # Let's see if we actually solve the problem\n",
    "                for x, y in zip(Input, Output):\n",
    "                    n = len(x)\n",
    "                    k = len(x[0])\n",
    "                    for i in range(n):\n",
    "                        for j in range(k):\n",
    "                            if v == 0 or v ==2:\n",
    "                                p1 = i%Q1\n",
    "                            else:\n",
    "                                p1 = (n-1-i)%Q1\n",
    "                            if v == 0 or v ==3:\n",
    "                                p2 = j%Q2\n",
    "                            else :\n",
    "                                p2 = (k-1-j)%Q2\n",
    "                           \n",
    "                            color1 = x[i][j]\n",
    "                            rule = (p1,p2,color1)\n",
    "                            \n",
    "                            if rule in Dict:\n",
    "                                color2 = 0 + Dict[rule]\n",
    "                            else:\n",
    "                                color2 = 0 + y[i][j]\n",
    "                            if color2 != y[i][j]:\n",
    "                                possible = False \n",
    "                if possible:\n",
    "                    Best_Dict = Dict\n",
    "                    Best_Q1 = Q1\n",
    "                    Best_Q2 = Q2\n",
    "                    Best_v = v\n",
    "                \n",
    "                \n",
    "    if Best_Dict == -1:\n",
    "        return -1 #meaning that we didn't find a rule that works for the traning cases\n",
    "    \n",
    "    #Otherwise there is a rule: so let's use it:\n",
    "    n = len(Test_Picture)\n",
    "    k = len(Test_Picture[0])\n",
    "    \n",
    "    answer = np.zeros((n,k), dtype = int)\n",
    "   \n",
    "    for i in range(n):\n",
    "        for j in range(k):\n",
    "            if Best_v == 0 or Best_v ==2:\n",
    "                p1 = i%Best_Q1\n",
    "            else:\n",
    "                p1 = (n-1-i)%Best_Q1\n",
    "            if Best_v == 0 or Best_v ==3:\n",
    "                p2 = j%Best_Q2\n",
    "            else :\n",
    "                p2 = (k-1-j)%Best_Q2\n",
    "           \n",
    "            color1 = Test_Picture[i][j]\n",
    "            rule = (p1, p2, color1)\n",
    "            if (p1, p2, color1) in Best_Dict:\n",
    "                answer[i][j] = 0 + Best_Dict[rule]\n",
    "            else:\n",
    "                answer[i][j] = 0 + color1\n",
    "                                            \n",
    "    return answer.tolist()\n",
    "\n",
    "def plot_task(task):\n",
    "    n = len(task[\"train\"]) + len(task[\"test\"])\n",
    "    fig, axs = plt.subplots(2, n, figsize=(4*n,8), dpi=50)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig_num = 0\n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n",
    "        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n",
    "        axs[0][fig_num].set_title(f'Train-{i} in')\n",
    "        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n",
    "        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n",
    "        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n",
    "        axs[1][fig_num].set_title(f'Train-{i} out')\n",
    "        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n",
    "        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n",
    "        fig_num += 1\n",
    "    for i, t in enumerate(task[\"test\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n",
    "        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n",
    "        axs[0][fig_num].set_title(f'Test-{i} in')\n",
    "        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n",
    "        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n",
    "        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n",
    "        axs[1][fig_num].set_title(f'Test-{i} out')\n",
    "        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n",
    "        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n",
    "        fig_num += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_train_samples(task, train_len=2):\n",
    "    \"\"\"\n",
    "    Plots the first train and test pairs of a specified task,\n",
    "    using same color scheme as the ARC app\n",
    "    \"\"\"\n",
    "    cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    fig, axs = plt.subplots(1, 2 * train_len, figsize=(7, 7))\n",
    "    for i in range(train_len):\n",
    "        axs[i * 2].imshow(task['train'][i]['input'], cmap=cmap, norm=norm)\n",
    "        axs[i * 2].axis('off')\n",
    "        axs[i * 2].set_title('Train Input')\n",
    "        axs[i * 2 + 1].imshow(task['train'][i]['output'], cmap=cmap, norm=norm)\n",
    "        axs[i * 2 + 1].axis('off')\n",
    "        axs[i * 2 + 1].set_title('Train Output')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_test(test_prediction, task_name, task_input):\n",
    "    \"\"\"\n",
    "    Plots the first train and test pairs of a specified task,\n",
    "    using same color scheme as the ARC app\n",
    "    \"\"\"\n",
    "    cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(7, 7))\n",
    "    axs[0].imshow(task_input, cmap=cmap, norm=norm)\n",
    "    axs[0].axis('off')\n",
    "    axs[0].set_title(f'Test Input {task_name}')\n",
    "    axs[1].imshow(test_prediction, cmap=cmap, norm=norm)\n",
    "    axs[1].axis('off')\n",
    "    axs[1].set_title(f'Test Prediction {task_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def unchanged_shape(task):\n",
    "    unchanged=True\n",
    "    for sample in task['train']:\n",
    "        array_train = np.array(sample['input'])\n",
    "        array_train[array_train > 0] = 1\n",
    "        array_test = np.array(sample['output'])\n",
    "        array_test[array_test > 0] = 1\n",
    "        \n",
    "        unchanged &= np.array_equal(array_train, array_test)\n",
    "\n",
    "    return unchanged\n",
    "\n",
    "def plot_picture(x):\n",
    "    plt.imshow(np.array(x), cmap = cmap, norm = norm)\n",
    "    plt.show()\n",
    "\n",
    "def flattener(pred):\n",
    "    str_pred = str([row for row in pred])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    return str_pred\n",
    "\n",
    "def get_moore_neighbours(color, cur_row, cur_col, nrows, ncols):\n",
    "    if cur_row + 1 < nrows: \n",
    "        bottom = color[cur_row + 1][cur_col]\n",
    "    else: \n",
    "        bottom = -1\n",
    "    \n",
    "    if cur_row - 1 >= 0:\n",
    "        top = color[cur_row - 1][cur_col]\n",
    "    else: \n",
    "        top = -1\n",
    "        \n",
    "    if cur_col - 1 >= 0: \n",
    "        left = color[cur_row][cur_col - 1]\n",
    "    else: \n",
    "        left = -1\n",
    "        \n",
    "    if cur_col + 1 < ncols: \n",
    "        right = color[cur_row][cur_col + 1]\n",
    "    else: \n",
    "        right = -1\n",
    "        \n",
    "    return top, bottom, left, right\n",
    "\n",
    "def get_tl_tr(color, cur_row, cur_col, nrows, ncols):    \n",
    "    if cur_row - 1 >= 0 and cur_col - 1 >= 0:\n",
    "        top_left = color[cur_row - 1][cur_col - 1]\n",
    "    else:\n",
    "        top_left = -1\n",
    "        \n",
    "    if cur_row - 1 >= 0 and cur_col + 1 < ncols:\n",
    "        top_right = color[cur_row - 1][cur_col + 1]\n",
    "    else:\n",
    "        top_right = -1\n",
    "        \n",
    "    if cur_row + 1 < nrows and cur_col + 1 < ncols:\n",
    "        bottom_right = color[cur_row + 1][cur_col + 1]\n",
    "    else:\n",
    "        bottom_right = -1\n",
    "        \n",
    "    if cur_row + 1 < nrows and cur_col - 1 >= 0:\n",
    "        bottom_left = color[cur_row + 1][cur_col - 1]\n",
    "    else:\n",
    "        bottom_left = -1\n",
    "        \n",
    "    return top_left, top_right, bottom_left, bottom_right\n",
    "\n",
    "def inside_borders(x, y, dx, dy, rows, columns):\n",
    "    return x + dx < rows and x + dx >= 0 and y + dy < columns and y + dy >= 0\n",
    "\n",
    "def bfs(row, col, visited, label, src_color_matrix, enable_diagonal):\n",
    "    color = src_color_matrix[row][col]\n",
    "    q = [(row, col)]\n",
    "    nrows, ncols = visited.shape\n",
    "    directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "    if enable_diagonal:\n",
    "        directions += [(1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "    size = 1\n",
    "    while len(q) != 0:\n",
    "        cur_row, cur_col = q.pop(0)\n",
    "        visited[cur_row][cur_col] = label\n",
    "        for dx, dy in directions:\n",
    "            if inside_borders(cur_row, cur_col, dx, dy, src_color_matrix.shape[0], src_color_matrix.shape[1]):\n",
    "                if not visited[cur_row + dx][cur_col + dy] and src_color_matrix[cur_row + dx][cur_col + dy] == color:\n",
    "                    q.append((cur_row + dx, cur_col + dy))\n",
    "                    visited[cur_row + dx][cur_col + dy] = label\n",
    "                    size += 1\n",
    "    \n",
    "    return size\n",
    "\n",
    "def get_connected_components_info(src_color_matrix, enable_diagonal):\n",
    "    connect_size = defaultdict(int)\n",
    "    rows, cols = src_color_matrix.shape\n",
    "    info_matrix = np.empty(src_color_matrix.shape, dtype=object)\n",
    "    visited = np.zeros_like(src_color_matrix)\n",
    "    label = 1\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if not visited[i][j]:\n",
    "                connect_size[label] = bfs(i, j, visited, label, src_color_matrix, enable_diagonal)\n",
    "                label += 1\n",
    "            info_matrix[i][j] = (connect_size[visited[i][j]], visited[i][j])\n",
    "    \n",
    "    return info_matrix\n",
    "\n",
    "def get_array_counters(array, row, unique_str, non_uniqe_str, init_color, is_max_indent):\n",
    "    values, counts = np.unique(array, return_counts=True)\n",
    "    val_count = dict(zip(values, counts))\n",
    "    if is_max_indent:\n",
    "        for i in range(0, 10):\n",
    "            if i not in val_count.keys():\n",
    "                row[non_uniqe_str + \" color:\" + str(i)] = 0\n",
    "            else:\n",
    "                row[non_uniqe_str + \" color:\" + str(i)] = val_count[i]\n",
    "            \n",
    "    row[unique_str] = values.reshape(-1).shape[0]\n",
    "    \n",
    "    return row\n",
    "\n",
    "def generate_box_features(row, src_color_matrix, indents):\n",
    "    rows_amount, columns_amount = src_color_matrix.shape[0], src_color_matrix.shape[1]\n",
    "    init_col, init_row = int(row['col']), int(row['row'])\n",
    "    for indent in indents:\n",
    "        start_col, start_row = max(init_col - indent, 0), max(init_row - indent, 0)\n",
    "        end_col, end_row = min(init_col + indent, columns_amount - 1), min(init_row + indent, rows_amount - 1)\n",
    "        row = get_array_counters(src_color_matrix[start_row : end_row + 1, start_col : end_col + 1], row,\n",
    "                           \"unique_colors in square indent \" + str(indent),\n",
    "                           \"non-unique_colors in square indent \" + str(indent), \n",
    "                           src_color_matrix[init_row][init_col], True)            \n",
    "    return row\n",
    "\n",
    "def generate_simple_neighbours_features(row, src_color_matrix, src_comp_info, src_comp_diag_info, comp_label_is_cycle, comp_label_size_ordered):\n",
    "    rows_amount, columns_amount = src_color_matrix.shape[0], src_color_matrix.shape[1]\n",
    "    cur_col, cur_row = int(row['col']), int(row['row'])\n",
    "    cur_color = src_color_matrix[cur_row][cur_col]\n",
    "    row['top_color'], row['bottom_color'], row['left_color'], row['right_color'] = get_moore_neighbours(src_color_matrix, \n",
    "                                                                      cur_row, cur_col, \n",
    "                                                                      rows_amount, columns_amount)\n",
    "    row['top_left_color'], row['top_right_color'], row['bottom_left_color'], row['bottom_right_color'] = get_tl_tr(src_color_matrix, cur_row, cur_col,\n",
    "                                                              rows_amount, columns_amount)\n",
    "\n",
    "    row['symmetry_position'] = cur_row + cur_col\n",
    "    \n",
    "#     row[\"unique_rows\"] = len(np.unique(src_color_matrix[cur_row,:]))\n",
    "#     row[\"unique_cols\"] = len(np.unique(src_color_matrix[:,cur_col]))\n",
    "#     row[\"unique\"] = len(np.unique(src_color_matrix[cur_row-5:cur_row+5,\n",
    "#                                                  cur_col-5:cur_col+5]))\n",
    "    row['until_border_col'] = columns_amount - 1 - cur_col\n",
    "    row['until_border_row'] = rows_amount - 1 - cur_row\n",
    "    \n",
    "    row['row_num%2'] = cur_row % 2\n",
    "    row['row_num%3'] = cur_row % 3\n",
    "    row['row_num%4'] = cur_row % 4\n",
    "    row['row_num%5'] = cur_row % 5\n",
    "    \n",
    "    row['col_num%2'] = cur_col % 2\n",
    "    row['col_num%3'] = cur_col % 3\n",
    "    row['col_num%4'] = cur_col % 4\n",
    "    row['col_num%5'] = cur_col % 5\n",
    "            \n",
    "    row[\"comp_size_diag\"], row[\"comp_num_diag\"] = src_comp_diag_info[cur_row][cur_col]\n",
    "    row[\"comp_size\"], row[\"comp_num\"] = src_comp_info[cur_row][cur_col]\n",
    "    \n",
    "    row[\"is_in_cycle\"] = comp_label_is_cycle[row[\"comp_num\"]]\n",
    "    \n",
    "    row[\"sorted_place_by_comp_size\"] = comp_label_size_ordered[row[\"comp_num\"]]\n",
    "    \n",
    "    directions = [(0, 1), (0, -1), (1, 0), (-1, 0), (1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "    for direction in directions:\n",
    "        if inside_borders(cur_row, cur_col, direction[0], direction[1], src_color_matrix.shape[0], src_color_matrix.shape[1]):\n",
    "            row[\"comp_num at dir \" + str(direction)] = src_comp_info[cur_row + direction[0]][cur_col + direction[1]][1]\n",
    "        else:\n",
    "            row[\"comp_num at dir \" + str(direction)] = -1\n",
    "    \n",
    "    if cur_col < rows_amount and cur_row < columns_amount:\n",
    "        row[\"symmetry_diag_pos\"] = int(src_color_matrix[cur_col][cur_row] == src_color_matrix[cur_row][cur_col])\n",
    "    else:\n",
    "        row[\"symmetry_diag_pos\"] = 0\n",
    "        \n",
    "    if rows_amount - 1 - cur_col >= 0 and columns_amount - 1 - cur_row >= 0 and rows_amount - 1 - cur_col < columns_amount and columns_amount - 1 - cur_row < rows_amount:\n",
    "        row[\"symmetry_diag_neg\"] = int(src_color_matrix[columns_amount - 1 - cur_row][rows_amount - 1 - cur_col] == src_color_matrix[cur_row][cur_col])\n",
    "    else:\n",
    "        row[\"symmetry_diag_neg\"] = 0\n",
    "        \n",
    "    row[\"symmetry_vertical\"] = int(src_color_matrix[cur_row][columns_amount - 1 - cur_col] == src_color_matrix[cur_row][cur_col])\n",
    "    row[\"symmetry_horizontal\"] = int(src_color_matrix[rows_amount - 1 - cur_row][cur_col] == src_color_matrix[cur_row][cur_col])\n",
    "    \n",
    "    row[\"rows_amount\"] = rows_amount\n",
    "    row[\"columns_amount\"] = columns_amount\n",
    "    \n",
    "    return row\n",
    "            \n",
    "def generate_line_features(row, src_color_matrix, indents):\n",
    "    rows_amount, columns_amount = src_color_matrix.shape[0], src_color_matrix.shape[1]\n",
    "    am_colors_left, am_colors_right = defaultdict(int), defaultdict(int)\n",
    "    am_colors_up, am_colors_down = defaultdict(int), defaultdict(int)\n",
    "    cur_col, cur_row = int(row['col']), int(row['row'])\n",
    "    for indent in indents:\n",
    "        start_col, start_row = max(cur_col - indent, 0), max(cur_row - indent, 0)\n",
    "        get_array_counters(src_color_matrix[cur_row + 1:, cur_col], row,\n",
    "                           \"unique_colors down indent \" + str(indent),\n",
    "                           \"non-unique_colors down indent \" + str(indent),\n",
    "                           src_color_matrix[cur_row][cur_col], True)\n",
    "        get_array_counters(src_color_matrix[start_row : cur_row, cur_col], row,\n",
    "                           \"unique_colors up indent \" + str(indent),\n",
    "                           \"non-unique_colors up indent \" + str(indent),\n",
    "                           src_color_matrix[cur_row][cur_col], True)\n",
    "        get_array_counters(src_color_matrix[cur_row, start_col : cur_col], row,\n",
    "                           \"unique_colors left indent \" + str(indent),\n",
    "                           \"non-unique_colors left indent \" + str(indent),\n",
    "                           src_color_matrix[cur_row][cur_col], True)\n",
    "        get_array_counters(src_color_matrix[cur_row, cur_col + 1:], row,\n",
    "                           \"unique_colors right indent \" + str(indent),\n",
    "                           \"non-unique_colors right indent \" + str(indent),\n",
    "                           src_color_matrix[cur_row][cur_col], True)\n",
    "        return row\n",
    "\n",
    "def compute_one_sample(input_color, target_color, comp_info, comp_info_diag, comp_label_is_cycle, comp_label_size_ordered, mode, i, j, k, indents, return_dict):\n",
    "    features = pd.DataFrame()\n",
    "    input_color_processed = input_color\n",
    "    output_color_processed = target_color\n",
    "    comp_info_processed = comp_info\n",
    "    comp_info_diag_processed = comp_info_diag\n",
    "    if mode == 'train':\n",
    "        # perform rotating\n",
    "#         input_color_processed = np.rot90(input_color_processed, i)\n",
    "#         output_color_processed = np.rot90(output_color_processed, i)\n",
    "#         comp_info_processed = np.rot90(comp_info_processed, i)\n",
    "#         comp_info_diag_processed = np.rot90(comp_info_diag_processed, i)\n",
    "        # perform horizontal flipping\n",
    "        if j == 1:\n",
    "            input_color_processed = np.flip(input_color_processed, 0)\n",
    "            output_color_processed = np.flip(output_color_processed, 0)\n",
    "            comp_info_processed = np.flip(comp_info_processed, 0)\n",
    "            comp_info_diag_processed = np.flip(comp_info_diag_processed, 0)\n",
    "        # perform vertical flipping\n",
    "        if k == 1:\n",
    "            input_color_processed = np.flip(input_color_processed, 1)\n",
    "            output_color_processed = np.flip(output_color_processed, 1)\n",
    "            comp_info_processed = np.flip(comp_info_processed, 1)\n",
    "            comp_info_diag_processed = np.flip(comp_info_diag_processed, 1)\n",
    "\n",
    "    nrows, ncols = input_color_processed.shape[0], input_color_processed.shape[1]\n",
    "    for row_num in range(nrows):\n",
    "        for col_num in range(ncols):\n",
    "            features = features.append(pd.DataFrame([[row_num, col_num, input_color_processed[row_num][col_num], \n",
    "                                                      output_color_processed[row_num][col_num]]], \n",
    "                                                      columns=['row', 'col', 'input_color', 'target_color']))\n",
    "\n",
    "    features = features.reset_index(drop=True)\n",
    "    features = features.apply(generate_simple_neighbours_features, args=(input_color_processed, comp_info_processed, comp_info_diag_processed, comp_label_is_cycle, comp_label_size_ordered), axis=1)\n",
    "    features = features.apply(generate_line_features, args=(input_color_processed, indents), axis=1)\n",
    "    features = features.apply(generate_box_features, args=(input_color_processed, indents), axis=1)\n",
    "        \n",
    "    return_dict[(i, j, k)] = features\n",
    "    \n",
    "    return features\n",
    "\n",
    "def dfs(parent, cur, src_matrix, visited_matrix, comp_label_is_cycle):\n",
    "    cur_row, cur_col = cur[0], cur[1]\n",
    "    parent_row, parent_col = parent[0], parent[1]\n",
    "    visited_matrix[cur_row, cur_col] = 1\n",
    "    directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "    for dx, dy in directions:\n",
    "        if inside_borders(cur_row, cur_col, dx, dy, src_matrix.shape[0], src_matrix.shape[1]):\n",
    "            new_x = cur_row + dx\n",
    "            new_y = cur_col + dy\n",
    "            if parent_row != -1 and src_matrix[new_x][new_y] != src_matrix[parent_row][parent_col]:\n",
    "                continue\n",
    "            if new_x == parent_row and new_y == parent_col:\n",
    "                continue\n",
    "            if visited_matrix[new_x][new_y]:\n",
    "                comp_label_is_cycle[src_matrix[new_x][new_y]] = 1\n",
    "                continue\n",
    "            dfs((cur_row, cur_col), (new_x, new_y), src_matrix, visited_matrix, comp_label_is_cycle)\n",
    "            \n",
    "def detect_cycles(src_matrix):\n",
    "    visited_matrix = np.zeros_like(src_matrix)\n",
    "    comp_label_is_cycle = defaultdict(int)\n",
    "    for i in range(src_matrix.shape[0]):\n",
    "        for j in range(src_matrix.shape[1]):\n",
    "            if not visited_matrix[i][j]:\n",
    "                dfs((-1, -1), (i, j), src_matrix, visited_matrix, comp_label_is_cycle)\n",
    "    \n",
    "    return comp_label_is_cycle\n",
    "            \n",
    "def compute_features(input_color, target_color, all_features, max_indent, mode):\n",
    "    manager = Manager()\n",
    "    return_dict = manager.dict()\n",
    "    processes = []\n",
    "    comp_info = get_connected_components_info(input_color, False) # Connected components classic\n",
    "    comp_info_diag = get_connected_components_info(input_color, True) # Connected components with diagonal connections\n",
    "    \n",
    "    comp_info_cycle = np.zeros_like(comp_info)\n",
    "    for i in range(comp_info.shape[0]):\n",
    "        for j in range(comp_info.shape[1]):\n",
    "            comp_info_cycle[i][j] = comp_info[i][j][1]\n",
    "            \n",
    "    comp_label_is_cycle = detect_cycles(comp_info_cycle)\n",
    "    \n",
    "    comp_label_size = defaultdict(int)\n",
    "    for i in range(comp_info.shape[0]):\n",
    "        for j in range(comp_info.shape[1]):\n",
    "            comp_label_size[comp_info[i][j][1]] = comp_info[i][j][0]\n",
    "            \n",
    "    comp_label_size = sorted(comp_label_size.items(), key=lambda x: x[1])\n",
    "    comp_label_size_ordered = defaultdict(int)\n",
    "    index = 0\n",
    "    prev = -1\n",
    "    for key, value in comp_label_size:\n",
    "        comp_label_size_ordered[key] = index\n",
    "        if prev != value:\n",
    "            index += 1\n",
    "        prev = value\n",
    "    \n",
    "#     for i in range(4):\n",
    "#         if input_color.shape[0] * input_color.shape[1] <= 100 and mode != 'test':\n",
    "#             for j in range(2):\n",
    "#                 for k in range(2):\n",
    "#                     p = Process(target=compute_one_sample, args=(input_color, target_color, comp_info, comp_info_diag, comp_label_is_cycle, comp_label_size_ordered, mode, i, j, k, max_indent, return_dict))\n",
    "#                     processes.append(p)\n",
    "#                     p.start()\n",
    "#         else:\n",
    "#             p = Process(target=compute_one_sample, args=(input_color, target_color, comp_info, comp_info_diag, comp_label_is_cycle, comp_label_size_ordered, mode, i, 0, 0, max_indent, return_dict))\n",
    "#             processes.append(p)\n",
    "#             p.start()\n",
    "\n",
    "#         if mode == 'test':\n",
    "#             break\n",
    "    p = Process(target=compute_one_sample, args=(input_color, target_color, comp_info, comp_info_diag, comp_label_is_cycle, comp_label_size_ordered, mode, 0, 0, 0, max_indent, return_dict))\n",
    "    processes.append(p)\n",
    "    p.start()   \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "        \n",
    "    for key, value in return_dict.items():\n",
    "        all_features = pd.concat([all_features, value])\n",
    "        \n",
    "    all_features = all_features.reset_index(drop=True)\n",
    "        \n",
    "    return all_features\n",
    "\n",
    "def features(task, max_indent, mode, test_indx=0):\n",
    "    num_train_pairs = len(task[mode])\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    if mode == 'train':\n",
    "        for train_indx in tqdm(range(num_train_pairs)):\n",
    "            nrows, ncols = len(task[mode][train_indx]['input']), len(task[mode][train_indx]['input'][0])\n",
    "            input_color = np.array(task[mode][train_indx]['input'])\n",
    "            target_color = np.array(task[mode][train_indx]['output'])\n",
    "            target_rows, target_cols = len(task[mode][train_indx]['output']), len(task[mode][train_indx]['output'][0])\n",
    "            \n",
    "            if (target_rows != nrows) or (target_cols != ncols):\n",
    "                return None, None, 0\n",
    "\n",
    "            features = compute_features(input_color, target_color, features, max_indent, 'train')\n",
    "    else:\n",
    "        nrows, ncols = len(task[mode][test_indx]['input']), len(task[mode][test_indx]['input'][0])\n",
    "        input_color = np.array(task[mode][test_indx]['input'])\n",
    "        target_color = input_color\n",
    "        \n",
    "        features = compute_features(input_color, target_color, features, max_indent, 'test')\n",
    "        \n",
    "    if features.target_color.unique().shape[0] <= 1 and mode == 'train':\n",
    "        return None, None, 0\n",
    "    \n",
    "    features = features.reset_index(drop=True)\n",
    "    target = features[\"target_color\"]\n",
    "    \n",
    "    del features[\"target_color\"]\n",
    "    features = features.reindex(sorted(features.columns), axis=1)\n",
    "    \n",
    "    return features, target, 1\n",
    "\n",
    "def match_figure_types(src_color_matrix):\n",
    "    return\n",
    "\n",
    "def apply_strategy(src, strategy, augment_functions):\n",
    "    for i in range(len(strategy)):\n",
    "        src = augment_functions[i](src, strategy[i])\n",
    "    return src\n",
    "\n",
    "def do_nothing(src, *args):\n",
    "    return src\n",
    "\n",
    "def try_to_match_simple_strategy(src, dst, augment_functions, strategy=[]):\n",
    "    if strategy is None:\n",
    "        return None\n",
    "    \n",
    "    row_replica_factor = dst.shape[0] / src.shape[0]\n",
    "    col_replica_factor = dst.shape[1] / src.shape[1]\n",
    "    \n",
    "    if not src.shape == dst.shape:\n",
    "        return None\n",
    "    \n",
    "    if strategy == []:\n",
    "        strategy = [0, 0, 0]\n",
    "        for rot_times in range(4):\n",
    "            for flip in range(2):\n",
    "                for do_unflip in range(2):\n",
    "                    strategy[0] = rot_times\n",
    "                    strategy[1] = flip\n",
    "                    strategy[2] = flip\n",
    "                    if do_unflip == 0:\n",
    "                        augment_functions[2] = do_nothing\n",
    "                    else:\n",
    "                        augment_functions[2] = np.flip\n",
    "                    result = apply_strategy(src.copy(), strategy, augment_functions)\n",
    "                    if np.array_equal(dst, result):\n",
    "                        return strategy\n",
    "        return None\n",
    "    else:\n",
    "        result = apply_strategy(src.copy(), strategy, augment_functions)\n",
    "    \n",
    "    if np.array_equal(dst, result):\n",
    "        return strategy\n",
    "    \n",
    "    return None\n",
    "\n",
    "def fill_preds(preds, nrows, ncols, sample_sub, task_id, task_num):\n",
    "    preds = preds.astype(int).reshape(nrows, ncols).tolist()\n",
    "    preds = flattener(preds)\n",
    "    sample_sub.loc[f'{task_id[:-5]}_{task_num}', 'output'] += preds\n",
    "    \n",
    "input_path = test_path\n",
    "all_task_ids = sorted(os.listdir(input_path))\n",
    "# random.shuffle(all_task_ids)\n",
    "\n",
    "sample_sub = pd.read_csv(data_path / 'sample_submission.csv')\n",
    "example_grid = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "all_ids_init = sample_sub['output_id'].values\n",
    "sample_sub = sample_sub.set_index('output_id')\n",
    "\n",
    "indents = [5]\n",
    "\n",
    "am_correct = 0\n",
    "attempts = 0\n",
    "attempts_total = 0\n",
    "\n",
    "for task_id in all_task_ids:\n",
    "    \n",
    "    attempts_total += 1\n",
    "    task_file = str(input_path / task_id)\n",
    "    \n",
    "    with open(task_file, 'r') as f:\n",
    "        task = json.load(f)\n",
    "        \n",
    "    need_only_recolor = unchanged_shape(task)\n",
    "    need_only_recolor = False\n",
    "    \n",
    "    train_X, train_Y, same_size = features(task, indents, 'train')\n",
    "   \n",
    "    if same_size == 1:\n",
    "        if need_only_recolor:\n",
    "            train_Y = train_Y[train_X['input_color'] > 0].reset_index(drop=True)\n",
    "            train_X = train_X[train_X['input_color'] > 0].reset_index(drop=True)\n",
    "\n",
    "        cols = list(train_X.columns)\n",
    "        desired_cat_features = []\n",
    "        cat_features = []\n",
    "        for feature in desired_cat_features:\n",
    "            cat_features.append(cols.index(feature))\n",
    "\n",
    "        cb = CatBoostClassifier(iterations=2000, verbose=0, loss_function=\"MultiClass\")\n",
    "        cb.fit(train_X, train_Y)\n",
    "        \n",
    "#         feature_scores = {}\n",
    "#         for score, name in zip(cb.feature_importances_, cb.feature_names_):\n",
    "#             feature_scores[name] = score\n",
    "\n",
    "#         feature_scores = sorted(feature_scores.items(), key=lambda kv: kv[1])\n",
    "#         for pair in feature_scores:\n",
    "#             if pair[1] > 1:\n",
    "#                 print(pair)\n",
    "\n",
    "        for task_num in range(len(task['test'])):\n",
    "            input_color = np.array(task['test'][task_num]['input'])\n",
    "            nrows, ncols = len(task['test'][task_num]['input']), len(task['test'][task_num]['input'][0])\n",
    "\n",
    "            test_X, _, __ = features(task, indents, 'test', task_num)\n",
    "            if need_only_recolor:\n",
    "                to_prediсt_X = test_X[test_X['input_color'] > 0]\n",
    "                preds = np.zeros((nrows * ncols, 1), dtype=int)\n",
    "                preds[test_X['input_color'] > 0] = cb.predict(to_prediсt_X)\n",
    "                preds = preds.reshape(nrows, ncols)\n",
    "            else:\n",
    "                preds = cb.predict(test_X).reshape(nrows, ncols)\n",
    "                \n",
    "            preds = preds.astype(int).tolist()\n",
    "            \n",
    "            sample_sub.loc[f'{task_id[:-5]}_{task_num}', 'output'] = flattener(preds)\n",
    "            \n",
    "#             if np.array_equal(preds.astype(int).reshape(nrows, ncols), task['test'][task_num]['output']):\n",
    "#                 am_correct += 1\n",
    "            \n",
    "#             print(\"Correct solutions: \", am_correct, \" of \", attempts_total)\n",
    "#             preds = preds.astype(int).reshape(nrows, ncols).tolist()\n",
    "#             plot_train_samples(task, 2)\n",
    "#             plot_test(preds, task_id, task['test'][task_num]['input'])\n",
    "\n",
    "Problems = all_ids_init\n",
    "for i in range(len(Problems)):\n",
    "    output_id = Problems[i]\n",
    "    task_id = output_id.split('_')[0]\n",
    "    pair_id = int(output_id.split('_')[1])\n",
    "    f = str(test_path / str(task_id + '.json'))\n",
    "   \n",
    "    with open(f, 'r') as read_file:\n",
    "        task = json.load(read_file)\n",
    "    \n",
    "    n = len(task['train'])\n",
    "    Input = [Defensive_Copy(task['train'][j]['input']) for j in range(n)]\n",
    "    Output = [Defensive_Copy(task['train'][j]['output']) for j in range(n)]\n",
    "    Input.append(Defensive_Copy(task['test'][pair_id]['input']))\n",
    "    \n",
    "    solution = Recolor([Input, Output])\n",
    "        \n",
    "    if solution != -1:\n",
    "        pred = flattener(solution)\n",
    "        sample_sub.loc[f'{task_id}_{pair_id}', 'output'] = pred\n",
    "            \n",
    "sample_sub.to_csv(\"submission.csv\")\n",
    "#67a3c6ac.json 74dd1130.json 68b16354.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
