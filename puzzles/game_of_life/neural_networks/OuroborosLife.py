import atexit
import gc
import time
from typing import List
from typing import Union

import numpy as np
import torch
import torch as pt
import torch.nn as nn

from neural_networks.FocalLoss import FocalLoss
from neural_networks.GameOfLifeBase import GameOfLifeBase
from utils.game import generate_random_board
from utils.game import life_step_3d


class OuroborosLife(GameOfLifeBase):
    """
    The idea of the Ouroboros Network is that rather than just predicting the next or previous state,
    we want to past, present and future simultaneously in the same network.

    The dataset is a sequence of 3 consecutive board states generated by life_step().

    The network takes the middle/present board state and attempts to predict all Past, Present and Future states

    The loss function computes the loss against the original training data, but also feeds back in upon itself.
    The output for Future is fed back in and it's Past is compared with the Present, likewise in reverse with the Paspt.
    """
    def __init__(self, in_channels=1, out_channels=3):
        assert out_channels % 2 == 1, f'{self.__class__.__name__}(out_channels={out_channels}) must be odd'

        super().__init__()
        self.in_channels  = in_channels
        self.out_channels = out_channels  # Past, Present and Future

        self.relu = nn.LeakyReLU()

        # 2**9 = 512 filters and kernel size of 3x3 to allow for full encoding of game rules
        # Pixels can see distance 5 neighbours, (hopefully) sufficient for delta=2 timesteps or out_channels=5
        # https://www.youtube.com/watch?v=H3g26EVADgY&feature=youtu.be&t=1h39m410s&ab_channel=JeremyHoward
        self.cnn_layers = nn.ModuleList([
            self.conv_block(self.in_channels, 512, kernel_size=(3,3)),
            self.conv_block(512, 256),
            self.conv_block(256, 128),
            self.conv_block(128,  64),
            self.conv_block( 64,  out_channels, output=True),
        ])

        # self.criterion = nn.BCELoss()
        self.criterion = FocalLoss()
        self.optimizer = pt.optim.RMSprop(self.parameters(), lr=0.01, momentum=0.9)
        self.scheduler = torch.optim.lr_scheduler.CyclicLR(
            self.optimizer,
            max_lr=1,
            base_lr=1e-3,
            step_size_up=100,
            mode='exp_range',
            gamma=0.8
        )


    def conv_block(self, in_f, out_f, kernel_size=(3,3), padding=1, stride=1, output=False, *args, **kwargs):
        """
        3x3 Conv2d + 2 * 1x1 Conv2d with Relu and BatchNorm between each layer
        Output layer has Sigmoid activation
        BatchNorm is not applied to input or output layers
        """
        mid_f = max(in_f, out_f)
        return nn.Sequential(
            nn.Conv2d(in_channels=in_f, out_channels=mid_f, kernel_size=kernel_size, stride=stride, padding=padding, padding_mode='circular', *args, **kwargs),
                self.relu,
                nn.BatchNorm2d(mid_f),
            nn.Conv2d(in_channels=mid_f, out_channels=mid_f, kernel_size=(1,1)),
                self.relu,
                nn.BatchNorm2d(mid_f),
            nn.Conv2d(in_channels=mid_f, out_channels=out_f, kernel_size=(1,1)),
                self.relu             if not output else nn.Sigmoid(),
                nn.BatchNorm2d(out_f) if not output else nn.Identity(),
        )


    # DOCS: https://towardsdatascience.com/understanding-input-and-output-shapes-in-convolution-network-keras-f143923d56ca
    # pytorch requires:    contiguous_format = (batch_size, channels, height, width)
    # tensorflow requires: channels_last     = (batch_size, height, width, channels)
    def cast_inputs(self, x: Union[List[np.ndarray], np.ndarray, torch.Tensor]) -> torch.Tensor:
        x = self.cast_to_tensor(x)
        if   x.dim() == 4: pass
        elif x.dim() == 3 and x.shape[0] == self.out_channels:           # x.shape = (channels, height, width)
            x = x.view(1, self.in_channels, x.shape[1], x.shape[2])   # x.shape = (batch_size, channels, height, width)
        else:
            x = super().cast_inputs(x)
        return x


    def forward(self, x):
        x = self.cast_inputs(x)
        output_shape = x.shape
        for n, layer_fn in enumerate(self.cnn_layers):
            x = layer_fn(x)
        return x


    def loss(self, outputs, timeline, inputs):
        dataset_loss    = self.loss_dataset(outputs, timeline, inputs)
        ouroboros_loss  = self.loss_ouroboros(outputs, timeline, inputs)
        arithmetic_mean = ( dataset_loss + ouroboros_loss ) / 2.0
        geometric_mean  = ( dataset_loss * ouroboros_loss ) ** (1/2)
        harmonic_mean   = 2.0 / ( 1.0/dataset_loss + 1.0/ouroboros_loss )
        return harmonic_mean


    def loss_dataset(self, outputs, timeline, inputs):
        # dataset_loss = torch.mean(torch.mean(( (timeline-outputs)**2 ).flatten(1), dim=1))  # average MSE per timeframe

        # FocalLoss(outputs, target) need to be in correct order
        dataset_loss = torch.mean(torch.tensor([
            self.criterion(outputs[b][t], timeline[b][t])
            for b in range(timeline.shape[0])
            for t in range(timeline.shape[1])
        ], requires_grad=True))
        return dataset_loss


    def loss_ouroboros(self, outputs, timeline, inputs):
        """
        Now we feed the output back into the input and compare second order losses
        t1=0 -> t2 = {2,3,4} | t1=1 -> t2 = {1,2,3,4} | t1=2 -> t2 = {0,1,2,3,4} | t1=3 -> t2 = {0,1,2,3} | t1=4 -> t2 = {0,1,2}
        outputs = [ Past2, Past1, Present, Future1, Future2 ]
        at t1=0: reinput == Past2   | reoutput = [ _,       _,       Past2,   Past1,   Present ]
        at t1=1: reinput == Past1   | reoutput = [ _,       Past2,   Past1,   Present, Future1 ]
        at t1=2: reinput == Present | reoutput = [ Past2,   Past1,   Present, Future1, Future2 ]
        at t1=3: reinput == Future1 | reoutput = [ Past1,   Present, Future1, Future2, _       ]
        at t1=4: reinput == Future2 | reoutput = [ Present, Future1, Future2, _,       _       ]
        """
        ouroboros_losses = []
        for t1 in range(self.out_channels):
            # reinput.shape = (batch_size, 1,            width, height)
            # reinput.shape = (batch_size, out_channels, width, height)
            reinput  = outputs[:,t1,:,:].unsqueeze(1)
            reoutput = self(reinput)
            t2_range = ( max(0, self.out_channels//2-t1), max(self.out_channels+1-t1, self.out_channels-1) )
            ouroboros_loss_per_timeline = []
            for b in range(timeline.shape[0]):
                for delta in range(-self.out_channels//2, self.out_channels//2+1):
                    t2 = t1 + delta
                    if not ( t2_range[0] <= t2 <= t2_range[1] ): continue  # invalid index
                    ouroboros_loss_per_timeline.append(
                        # pt.mean( (timeline[b][t1] - reoutput[b][t2])**2 )
                        self.criterion(reoutput[b][t2], timeline[b][t1])
                    )
            ouroboros_losses += ouroboros_loss_per_timeline

        ouroboros_loss = pt.mean(pt.tensor(ouroboros_losses)).requires_grad_(True)
        return ouroboros_loss


    def accuracy(self, outputs, timeline, inputs) -> float:
        """ Count the number of 100% accuracy boards predicted """
        # noinspection PyTypeChecker
        accuracies = pt.tensor([
            pt.all( outputs[b][t] == timeline[b][t] )
            for b in range(timeline.shape[0])
            for t in range(timeline.shape[1])
        ])
        accuracy = pt.mean(accuracies.to(pt.float))
        return accuracy.detach().item()


    def fit(self, epochs=10000, batch_size=25, max_delta=10):
        gc.collect()
        torch.cuda.empty_cache()
        atexit.register(model.save)
        atexit.register(torch.cuda.empty_cache)
        atexit.register(gc.collect)
        self.train()
        self.unfreeze()
        try:
            time_start  = time.perf_counter()
            board_count = 0
            for epoch in range(1, epochs+1):
                epoch_start = time.perf_counter()
                timelines_batch = np.array([
                    life_step_3d(generate_random_board(), max_delta)
                    for _ in range(batch_size)
                ])
                losses           = []
                dataset_losses   = []
                ouroboros_losses = []
                accuracies       = []
                d = self.out_channels // 2  # In theory this should work for 5 or 7 channels
                for t in range(d, max_delta - d):
                    inputs_np   = timelines_batch[:, np.newaxis, t,:,:]  # (batch_size=10, channels=1,  width=25, height=25)
                    timeline_np = timelines_batch[:, t-d:t+d+1,    :,:]  # (batch_size=10, channels=10, width=25, height=25)
                    inputs   = pt.tensor(inputs_np).to(self.device).to(pt.float32)
                    timeline = pt.tensor(timeline_np).to(self.device).to(pt.float32)

                    self.optimizer.zero_grad()
                    outputs  = self(inputs)
                    accuracy        = model.accuracy(outputs, timeline, inputs)  # torch.sum( outputs.to(torch.cast_bool) == expected.to(torch.cast_bool) ).cpu().numpy() / np.prod(outputs.shape)
                    dataset_loss    = self.loss_dataset(outputs, timeline, inputs)
                    ouroboros_loss  = self.loss_ouroboros(outputs, timeline, inputs)
                    # loss            = dataset_loss + ouroboros_loss
                    loss            = 2.0 / ( 1.0/dataset_loss + 1.0/ouroboros_loss )
                    loss.backward()
                    self.optimizer.step()
                    self.scheduler.step()

                    board_count += 1
                    losses.append(loss.detach().item())
                    dataset_losses.append(dataset_loss.detach().item())
                    ouroboros_losses.append(ouroboros_loss.detach().item())
                    accuracies.append(accuracy)
                    torch.cuda.empty_cache()

                epoch_time = time.perf_counter() - epoch_start
                print(f'epoch: {epoch:4d} | boards: {board_count:5d} | loss: {np.mean(losses):.8f} | dataset: {np.mean(dataset_losses):.8f} | ouroboros: {np.mean(ouroboros_losses):.8f} | accuracy = {np.mean(accuracies):.8f} | time: {1000*epoch_time/batch_size:.3f}ms/board')
            time_taken = time.perf_counter() - time_start
        except KeyboardInterrupt: pass
        finally:
            model.save()
            atexit.unregister(model.save)
            torch.cuda.empty_cache()
            gc.collect()


if __name__ == '__main__':
    # PYTHONUNBUFFERED=1 time python3 ./neural_networks/GameOfLifeReverseOneStep.py | tee ./neural_networks/models/GameOfLifeReverseOneStep.log
    model = OuroborosLife()
    model.fit()
    # train(model, reverse_input_output=True)
