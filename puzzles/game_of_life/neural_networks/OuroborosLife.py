import atexit
import gc
import time
from typing import List
from typing import Tuple
from typing import Union

import numpy as np
import torch
import torch as pt
import torch.nn as nn

from neural_networks.GameOfLifeBase import GameOfLifeBase
from neural_networks.modules.FocalLoss import FocalLoss
from utils.game import generate_random_board
from utils.game import life_step_3d


class OuroborosLife(GameOfLifeBase):
    """
    The idea of the Ouroboros Network is that rather than just predicting the next or previous state,
    we want to past, present and future simultaneously in the same network.

    The dataset is a sequence of 3 consecutive board states generated by life_step().

    The network takes the middle/present board state and attempts to predict all Past, Present and Future states

    The loss function computes the loss against the original training data, but also feeds back in upon itself.
    The output for Future is fed back in and it's Past is compared with the Present, likewise in reverse with the Paspt.
    """
    @property
    def filename(self) -> str:
        """ ./models/OuroborosLife3.pth || ./models/OuroborosLife5.pth """
        return super().filename.replace('.pth', f'{self.out_channels}.pth')


    def __init__(self, in_channels=1, out_channels=3):
        """
        TODO:
        - Create split blocks that return: [identity, avgpool, maxpool ]  # do we need 3x3 convolution with fixed weights
        - Basically find a way to count neighbours
        - reduce model size
        - add in dense layer at end + middle (as opposed to deconvolution???)
        """
        assert out_channels % 2 == 1, f'{self.__class__.__name__}(out_channels={out_channels}) must be odd'

        super().__init__()
        self.in_channels  = in_channels
        self.out_channels = out_channels  # Past, Present and Future

        self.relu    = nn.LeakyReLU()     # combines with nn.init.kaiming_normal_()
        self.dropout = nn.Dropout(p=0.2)

        # 2**9 = 512 filters and kernel size of 3x3 to allow for full encoding of game rules
        # Pixels can see distance 5 neighbours, (hopefully) sufficient for delta=2 timesteps or out_channels=5
        # https://www.youtube.com/watch?v=H3g26EVADgY&feature=youtu.be&t=1h39m410s&ab_channel=JeremyHoward
        self.cnn_layers = nn.ModuleList([
            # Previous pixel state requires information from distance 2, so we need two 3x3 convolutions
            nn.Conv2d(in_channels=in_channels, out_channels=512,  kernel_size=(5,5), padding=2, padding_mode='circular'),
            nn.Conv2d(in_channels=512,   out_channels=256,  kernel_size=(1,1)),
            nn.Conv2d(in_channels=256,   out_channels=128,  kernel_size=(1,1)),

            nn.Conv2d(in_channels=1+128, out_channels=128,  kernel_size=(3,3), padding=1, padding_mode='circular'),
            nn.Conv2d(in_channels=128,   out_channels=512,  kernel_size=(1,1)),
            nn.Conv2d(in_channels=512,   out_channels=256,  kernel_size=(1,1)),
            nn.Conv2d(in_channels=256,   out_channels=128,  kernel_size=(1,1)),

            # # Deconvolution + Convolution allows neighbouring pixels to share information to simulate forward play
            # # This creates a 52x52 grid of interspersed cells that can then be downsampled back down to 25x25
            nn.ConvTranspose2d(in_channels=1+128, out_channels=512,  kernel_size=(3,3), stride=2, dilation=1),
            nn.Conv2d(in_channels=512,   out_channels=256,   kernel_size=(1,1)),
            nn.Conv2d(in_channels=256,   out_channels=64,    kernel_size=(1,1)),
            nn.Conv2d(in_channels=64,    out_channels=128,   kernel_size=(3,3), stride=2),  # undo deconvolution

            nn.Conv2d(in_channels=1+128, out_channels=64,    kernel_size=(1,1)),
            nn.Conv2d(in_channels=64,    out_channels=32,    kernel_size=(1,1)),
            nn.Conv2d(in_channels=32,    out_channels=16,    kernel_size=(1,1)),
            nn.Conv2d(in_channels=1+16,  out_channels=out_channels, kernel_size=(1,1)),
        ])
        self.batchnorm_layers = nn.ModuleList([
            nn.BatchNorm2d(cnn_layer.out_channels)
            for cnn_layer in self.cnn_layers
        ])


        # self.criterion = nn.BCELoss()
        self.criterion = FocalLoss()
        # self.criterion = nn.MSELoss()
        self.optimizer = pt.optim.RMSprop(self.parameters(), lr=0.01, momentum=0.9)
        self.scheduler = torch.optim.lr_scheduler.CyclicLR(
            self.optimizer,
            max_lr=1e-4,
            base_lr=1e-6,
            step_size_up=100,
            mode='exp_range',
            gamma=0.8
        )

    # def load(self):
    #     super().load()
    #     self.apply(self.weights_init)


    def forward(self, x):
        x = input = self.cast_inputs(x)
        for n, (cnn_layer, batchnorm_layer) in enumerate(zip(self.cnn_layers, self.batchnorm_layers)):
            if cnn_layer.in_channels > 1 and cnn_layer.in_channels % 2 == 1:   # autodetect 1+in_channels == odd number
                x = torch.cat([ x, input ], dim=1)                     # passthrough original cell state
            x = cnn_layer(x)
            if n != len(self.cnn_layers)-1:
                x = self.relu(x)
                if n != 1:               # Don't apply dropout to the first layer
                    x = self.dropout(x)  # BatchNorm eliminates the need for Dropout in some cases cause BN provides similar regularization benefits as Dropout intuitively"
                x = batchnorm_layer(x)   # batchnorm goes after activation
            else:
                x = torch.sigmoid(x)  # output requires sigmoid activation
        return x


    # DOCS: https://towardsdatascience.com/understanding-input-and-output-shapes-in-convolution-network-keras-f143923d56ca
    # pytorch requires:    contiguous_format = (batch_size, channels, height, width)
    # tensorflow requires: channels_last     = (batch_size, height, width, channels)
    def cast_inputs(self, x: Union[List[np.ndarray], np.ndarray, torch.Tensor]) -> torch.Tensor:
        x = self.cast_to_tensor(x)
        if   x.dim() == 4: pass
        elif x.dim() == 3 and x.shape[0] == self.out_channels:           # x.shape = (channels, height, width)
            x = x.view(1, self.in_channels, x.shape[1], x.shape[2])   # x.shape = (batch_size, channels, height, width)
        else:
            x = super().cast_inputs(x)
        return x


    # def loss(self, outputs, timeline, inputs):
    #     dataset_loss    = self.loss_dataset(outputs, timeline, inputs)
    #     ouroboros_loss  = self.loss_ouroboros(outputs, timeline, inputs)
    #     arithmetic_mean = ( dataset_loss + ouroboros_loss ) / 2.0
    #     geometric_mean  = ( dataset_loss * ouroboros_loss ) ** (1/2)
    #     harmonic_mean   = 2.0 / ( 1.0/dataset_loss + 1.0/ouroboros_loss )
    #     return arithmetic_mean
    #
    #
    # def loss_ouroboros(self, outputs, timeline, inputs):
    #     """
    #     Now we feed the output back into the input and compare second order losses
    #     t1=0 -> t2 = {2,3,4} | t1=1 -> t2 = {1,2,3,4} | t1=2 -> t2 = {0,1,2,3,4} | t1=3 -> t2 = {0,1,2,3} | t1=4 -> t2 = {0,1,2}
    #     outputs = [ Past2, Past1, Present, Future1, Future2 ]
    #     at t1=0: reinput == Past2   | reoutput = [ _,       _,       Past2,   Past1,   Present ]
    #     at t1=1: reinput == Past1   | reoutput = [ _,       Past2,   Past1,   Present, Future1 ]
    #     at t1=2: reinput == Present | reoutput = [ Past2,   Past1,   Present, Future1, Future2 ]
    #     at t1=3: reinput == Future1 | reoutput = [ Past1,   Present, Future1, Future2, _       ]
    #     at t1=4: reinput == Future2 | reoutput = [ Present, Future1, Future2, _,       _       ]
    #     """
    #     ouroboros_losses = []
    #     for t1 in range(self.out_channels):
    #         # reinput.shape = (batch_size, 1,            width, height)
    #         # reinput.shape = (batch_size, out_channels, width, height)
    #         reinput  = outputs[:,t1,:,:].unsqueeze(1)
    #         reoutput = self(reinput)
    #         t2_range = ( max(0, self.out_channels//2-t1), max(self.out_channels+1-t1, self.out_channels-1) )
    #         ouroboros_loss_per_timeline = []
    #         for b in range(timeline.shape[0]):
    #             for delta in range(-self.out_channels//2+1, self.out_channels//2+1):
    #                 t2 = t1 + delta
    #                 if not ( t2_range[0] <= t2 <= t2_range[1] ): continue  # invalid index
    #                 ouroboros_loss_per_timeline.append(
    #                     # pt.mean( (timeline[b][t1] - reoutput[b][t2])**2 )
    #                     self.criterion(reoutput[b][t2], timeline[b][t1])
    #                 )
    #         ouroboros_losses += ouroboros_loss_per_timeline
    #
    #     ouroboros_loss = pt.mean(pt.tensor(ouroboros_losses)).requires_grad_(True)
    #     return ouroboros_loss
    #
    #
    # def accuracy_dataset(self, outputs, timeline, inputs) -> float:
    #     """
    #     Count the number of 100% accuracy boards predicted
    #     accuracy == 0.666 + output_channels == 3 means:
    #         Present and Future boards have been correctly predicted, but Past is still not fully solved
    #     """
    #     # noinspection PyTypeChecker
    #     accuracies = pt.tensor([
    #         pt.all( self.cast_bool(outputs[b][t]) == self.cast_bool(timeline[b][t]) )                      # percentage boards correct
    #         # pt.mean(( self.cast_bool(outputs[b][t]) == self.cast_bool(timeline[b][t]) ).to(pt.float32))  # percentage pixels correct
    #         for b in range(timeline.shape[0])
    #         for t in range(timeline.shape[1])
    #     ])
    #     accuracy = pt.mean(accuracies.to(pt.float))
    #     return accuracy.detach().item()


    def loss_dataset(self, outputs, timeline, inputs, exclude_past=True):
        # Exclude past losses to avoid the many-pasts to one-future problem
        if exclude_past:
            t_present = self.out_channels//2
            outputs   = outputs[  :, t_present:, :, : ]
            timeline  = timeline[ :, t_present:, :, : ]

        ### Other ways of computing dataset loss
        # dataset_loss = torch.mean(torch.mean(( (timeline-outputs)**2 ).flatten(1), dim=1)) # average MSE per timeframe
        # dataset_loss = torch.sum(torch.tensor([
        #     self.criterion(outputs[b][t], timeline[b][t])  # NOTE: FocalLoss(outputs, target) needed in correct order
        #     for b in range(timeline.shape[0])
        #     for t in range(timeline.shape[1])
        # ], requires_grad=True))

        dataset_loss = self.criterion(outputs, timeline)
        return dataset_loss


    def loss_accuracy_ouroboros(self, outputs, timeline, inputs) -> Tuple[pt.Tensor, pt.Tensor, pt.Tensor]:
        """
        Compute simplified losses for each head, only comparing reoutputs with timeline[t_present]
        reinput    = t1=0 = Past | t1=1 = Present | t1=2 = Future
        reoutput   = [ Past2, Past, Present ]@t=0, [ Past, Present, Future ]@t=1, [ Present, Future, Future2 ]@t=2
        """
        losses     = pt.zeros(self.out_channels, dtype=pt.float32, requires_grad=True).to(self.device)
        acc_boards = pt.zeros(self.out_channels, dtype=pt.float32, requires_grad=False).to(self.device)
        acc_pixels = pt.zeros(self.out_channels, dtype=pt.float32, requires_grad=False).to(self.device)
        for t_input in range(self.out_channels):
            t_present = self.out_channels//2 - t_input
            reinput   = outputs[:,t_input,:,:].unsqueeze(1)
            reoutputs = self(reinput)

            # Losses get calculated for present and all future datapoints
            for d in range(self.out_channels):
                if reoutputs.shape[1] <= t_present + d: break
                if timeline.shape[1]  <= t_input   + d: break
                losses[t_input] += self.criterion(reoutputs[:,t_present+d,:,:], timeline[:,t_input+d,:,:])

            # Accuracy is based only on the self-referential present
            pixels_correct       = ((reoutputs[:,t_present,:,:] > 0.5) == (timeline[:,t_input,:,:] > 0.5)).to(pt.float).detach()
            acc_pixels[t_input] +=  pixels_correct.mean()
            acc_boards[t_input] += (pixels_correct.mean(dim=1) == 1.0).to(pt.float).mean()
        return losses, acc_pixels, acc_boards




    def fit(self, epochs=100_000, batch_size=25, max_delta=25, timeout=0):
        gc.collect()
        torch.cuda.empty_cache()
        atexit.register(model.save)
        self.train()
        self.unfreeze()
        print(self)
        try:
            # timelines_batch = np.array([
            #     life_step_3d(generate_random_board(), max_delta)
            #     for _ in range(batch_size)
            # ])
            time_start  = time.perf_counter()
            board_count = 0
            dataset_accuracies = [0]
            for epoch in range(1, epochs+1):
                if np.min(dataset_accuracies[-10:]) == 1.0: break  # we have reached 100% accuracy
                if timeout and timeout < time.perf_counter() - time_start: break

                epoch_start = time.perf_counter()
                timelines_batch = np.array([
                    life_step_3d(generate_random_board(), max_delta)
                    for _ in range(batch_size)
                ])
                epoch_ds_losses  = []
                epoch_losses     = []
                epoch_acc_pixels = []
                epoch_acc_boards = []
                d = self.out_channels // 2  # In theory this should work for 5 or 7 channels
                for t in range(d, max_delta - d):
                    inputs_np   = timelines_batch[:, np.newaxis, t,:,:]  # (batch_size=10, channels=1,  width=25, height=25)
                    timeline_np = timelines_batch[:, t-d:t+d+1,    :,:]  # (batch_size=10, channels=10, width=25, height=25)
                    inputs      = pt.tensor(inputs_np).to(self.device).to(pt.float32)
                    timeline    = pt.tensor(timeline_np).to(self.device).to(pt.float32)

                    self.optimizer.zero_grad()
                    outputs      = self(inputs)
                    dataset_loss = self.loss_dataset(outputs, timeline, inputs, exclude_past=True)
                    orb_losses, acc_pixels, acc_boards = model.loss_accuracy_ouroboros(outputs, timeline, inputs)
                    loss = pt.mean(orb_losses) + dataset_loss
                    loss.backward()
                    self.optimizer.step()
                    self.scheduler.step()

                    board_count += batch_size
                    epoch_ds_losses.append(dataset_loss.detach().item())
                    epoch_losses.append(orb_losses.detach())
                    epoch_acc_pixels.append(acc_pixels.detach())
                    epoch_acc_boards.append(acc_boards.detach())
                    torch.cuda.empty_cache()

                dataset_accuracies.append( pt.stack(epoch_acc_boards).min() )
                epoch_loss      = f"{100*np.mean(epoch_ds_losses):.6f} : " + " ".join([ f'{100*n:.6f}' for n in pt.stack(epoch_losses).mean(dim=0).tolist()     ])
                epoch_acc_pixel = " ".join([ f'{n:.3f}'     for n in pt.stack(epoch_acc_pixels).mean(dim=0).tolist() ])
                epoch_acc_board = " ".join([ f'{n:.3f}'     for n in pt.stack(epoch_acc_boards).mean(dim=0).tolist() ])

                epoch_time = time.perf_counter() - epoch_start
                time_taken = time.perf_counter() - time_start
                if epoch <= 10 or epoch <= 100 and epoch % 10 == 0 or epoch % 100 == 0:
                    print(f'epoch: {epoch:4d} | boards: {board_count:5d} | loss: {epoch_loss} | pixels = {epoch_acc_pixel} | boards = {epoch_acc_board} | time: {time_taken//60:.0f}:{time_taken%60:02.0f} @ {1000*epoch_time//batch_size:3.0f}ms')
                    # print(f'epoch: {epoch:4d} | boards: {board_count:5d} | loss: {np.mean(epoch_losses):.6f} | ouroboros: {np.mean(ouroboros_losses):.6f} | dataset: {np.mean(dataset_losses):.6f} | accuracy = {np.mean(epoch_accuracies):.6f} | time: {1000*epoch_time//batch_size}ms/board | {time_taken//60:.0f}:{time_taken%60:02.0f}')
                if epoch % 100 == 0:
                    model.save()

        except KeyboardInterrupt: pass
        finally:
            model.save()
            atexit.unregister(model.save)
            torch.cuda.empty_cache()
            gc.collect()


if __name__ == '__main__':
    # PYTHONUNBUFFERED=1 time python3 ./neural_networks/GameOfLifeReverseOneStep.py | tee ./neural_networks/models/GameOfLifeReverseOneStep.log
    model = OuroborosLife()
    model.fit()
    # train(model, reverse_input_output=True)
